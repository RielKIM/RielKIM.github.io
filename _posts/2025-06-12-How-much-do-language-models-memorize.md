---
layout: post
title: "How much do language models memorize?"
date: 2025-06-12
excerpt: "AI는 베끼는 걸까, 배우는 걸까? AI의 '암기력' 비밀 파헤치기!"
tags: ["GPT 모델 용량(GPT Model Capacity)","의도하지 않은 기억(Unintended Memorization)","일반화(Generalization)","멤버십 추론(Membership Inference)","Kolmogorov 복잡도(Kolmogorov Complexity)"]
comments: true
---

안녕하세요! 요즘 우리 삶 곳곳에서 활약하는 인공지능(AI), 정말 신기하지 않으신가요? 문득 이런 궁금증이 생깁니다. "AI는 정말 우리가 하는 말을 이해하는 걸까, 아니면 그냥 인터넷에 있는 수많은 글을 통째로 외워서 그럴듯하게 앵무새처럼 따라 하는 걸까?"

마치 공부 잘하는 학생을 볼 때 "저 친구는 머리가 좋아서 이해를 잘하는 걸까, 아니면 그냥 교과서를 달달 외운 걸까?" 궁금해하는 것과 같죠.

최근에 바로 이 질문에 대한 아주 흥미로운 답을 제시한 논문이 나왔습니다. 오늘은 이 똑똑한 과학자들이 어떻게 AI의 '암기력'과 '이해력'을 구분했는지, 그 비밀을 함께 파헤쳐 보겠습니다!

#### 1단계: AI의 '뇌 용량' 재보기: 암기력의 한계는 어디까지?

과학자들은 먼저 AI의 순수한 '암기력'을 측정하고 싶었어요. 그래서 아주 기발한 방법을 사용합니다. AI에게 아무 의미 없는 단어들을 무작위로 섞어서 만든, 규칙도 맥락도 없는 자료를 주고 외우게 시켰죠. (예: "고양이 사과 우주 피아노...")

이런 정보는 이해할 수 없으니, 오직 암기력에만 의존해야 합니다. 결과는 어땠을까요?

<figure>
    <img src="/2025-06-12-How-much-do-language-models-memorize/image.svg">
</figure>

위 그래프는 마치 크기가 다른 가방에 물건을 채우는 것과 같아요. 처음에는 주는 대로 족족 외우며 암기량이 늘어나지만(선이 위로 상승), 어느 순간 선이 평평해집니다. 가방이 꽉 찬 것처럼, AI의 암기 용량이 한계에 도달한 것이죠. 당연히 더 큰 AI(초록색 선)가 더 많은 정보를 외울 수 있었습니다.

이 실험을 통해 놀라운 사실을 발견했습니다.
Display: AI의 암기 용량은 예측 가능하다 (부품 1개당 약 3.6비트).
AI의 크기만 알면 얼마나 암기할 수 있는지 계산할 수 있게 된 것입니다!

#### 2단계: 뇌가 꽉 찼을 때 벌어지는 마법! '더블 디센트' 현상

자, 이제 AI에게 의미 없는 정보 대신 실제 글(뉴스, 소설 등)을 뇌 용량보다 훨씬 많이 주면 어떻게 될까요? 상식적으로는 과부하가 걸려 성능이 나빠질 것 같죠? 하지만 놀라운 반전이 일어났습니다.

[image (1).svg](2025-06-12-How-much-do-language-models-memorize/image%20%281%29.svg)<!-- {"embed":"true"} -->

이 그래프는 AI 학습의 놀라운 비밀을 보여줍니다.

1. ① 첫 번째 하강: 처음엔 공부하는 만큼 점수가 좋아집니다. (실수가 줄어듦)
2. ② 갑작스러운 상승: 그런데 학습량이 뇌 용량과 딱 맞아떨어지는 지점(그래프의 뾰족한 부분)에서 갑자기 점수가 확 나빠집니다! AI가 배운 내용을 억지로 다 외우려고만 하다가, 응용 문제에서 실수를 연발하는 '혼란' 상태에 빠진 것입니다.
3. ③ 두 번째 하강: 하지만 여기서 포기하지 않고 학습량을 훨씬 더 늘리자, AI는 "아, 도저히 다 못 외우겠다!"라고 깨닫습니다. 그리고는 단순 암기를 포기하고 데이터 속의 규칙과 원리를 '이해'하는 전략으로 바꿉니다. 그 결과, 처음 보는 문제도 잘 푸는 '일반화' 단계에 도달하며 점수가 다시 아주 좋아집니다!

이것이 바로 이 연구의 핵심 발견입니다.
Display: 학습 데이터가 AI의 용량을 초과하면, AI는 단순 암기를 넘어 일반화(이해)를 시작한다.
AI에게는 오히려 시련이 성장의 기회가 된 셈이네요!

#### 3단계: AI는 무엇을 편애할까? 희귀한 기억의 비밀

그렇다면 AI는 진짜 글을 공부할 때, 어떤 내용을 특별히 더 잘 외울까요? 평범한 문장일까요, 아니면 특이한 문장일까요?

[image (2).svg](2025-06-12-How-much-do-language-models-memorize/image%20%282%29.svg)<!-- {"embed":"true"} -->

결과는 명확했습니다. 그래프에서 볼 수 있듯이, 데이터가 희귀하고 특이할수록(Y축 위쪽) AI는 더 강하게 암기(X축 오른쪽)했습니다.

실제로 AI가 가장 잘 외운 문장 목록(표 5)을 살펴보니 더욱 놀라웠습니다. 대부분이 영어를 학습했음에도 불구하고, 가장 잘 외운 것은 일본어, 중국어 문장, 프로그래밍 코드, 반복되는 특이한 문구 등이었습니다. 인터넷 전체에서 아주 가끔 나타나는 '희귀템'이었기 때문이죠.

Display: AI는 평범한 정보보다 희귀하고 특이한 정보를 더 강하게 암기한다.
이는 우리에게 중요한 점을 시사합니다. 인터넷에 드물게 올라온 나의 개인정보나 특이한 글이, AI에게는 오히려 더 '기억에 남는' 정보가 될 수 있다는 뜻이니까요.

### 결론: AI는 암기왕일까, 이해왕일까?

오늘 우리는 AI의 학습법에 대한 세 가지 중요한 비밀을 알게 되었습니다.

1. AI의 암기력은 측정 가능하며 한계가 있다.
2. AI는 암기력의 한계를 넘어서는 학습을 통해, 암기를 포기하고 '이해'의 단계로 성장한다.
3. AI는 평범한 것보다 희귀하고 특이한 것을 더 잘 기억한다.

결론적으로 AI는 단순한 '암기왕'이 아닙니다. 특정 조건을 만족하면 데이터의 패턴과 원리를 파악하는 '이해왕'으로 거듭날 수 있는 존재입니다.

이러한 연구는 우리가 AI를 더 똑똑하게 만들 뿐만 아니라, 잠재적인 위험(개인정보 암기 등)을 막고 더 안전하게 만드는 데 큰 도움을 줍니다. AI의 세계, 알면 알수록 정말 신기하고 흥미롭지 않나요? 다음에 더 재미있는 AI 이야기로 돌아오겠습니다.

URL : [How much do language models memorize?](https://arxiv.org/abs/2505.24832)
